{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume Sampling vs projection DPP for low rank approximation\n",
    "## Introduction\n",
    "#### In this notebook we compare the volume sampling and projection DPP for low rank approximation.\n",
    "We recall the result proved in the article [DRVW]:\\\\\n",
    "Let S be a random subset of k columns of X chosen with probability: $$P(S) = \\frac{1}{Z_{k}} det(X_{.,S}^{T}X_{.,S})$$ with $$Z_{k} = \\sum\\limits_{S \\subset [N], |S| = k} det(X_{.,S}^{T}X_{.,S})$$\n",
    "Then\n",
    "$$\\begin{equation}\n",
    "E(\\| X - \\pi_{X_{.,S}}(X) \\|_{Fr}^{2}) \\leq (k+1)\\| X - \\pi_{k}(X) \\|_{Fr}^{2}\n",
    "\\end{equation}$$\n",
    "\n",
    "\n",
    "We can prove that the volume sampling distribution is a mixture of projection DPPs distributions..., in particular one projection DPP distribution stands out for the problem of low rank approximation: ....\\\\\n",
    "For the moment, there is no analytical expression for $$\\begin{equation}\n",
    "E(\\| X - \\pi_{X_{.,S}}(X) \\|_{Fr}^{2}) \n",
    "\\end{equation}$$ under the distribution of projection DPP.\\\\\n",
    "However, we can calculate this quantity using simulation on some matrices representing cloud points with some specific geometric constraints.\n",
    "\n",
    "Let $$X \\in R^{n \\times m}$$ a matrix representing a cloud of points.\n",
    "We can write the SVD of $$X = UDV^{T}$$  \n",
    "In this notebook we investigate the influence of some structures enforced to V and D on the expected error expressed above for different algorithms: Volume Sampling, Projection DPP and the deterministic algorithm.  \n",
    "As for the Volume Sampling distribution, we can express the expected approximation error using only the elements of D. We can test this theoretical property in the next Numerical Study below. However, there is no closed formula (for the moment) for the expected approximation error under Projection DPP distribution. We will see in the Numerical Study section, that this value cannot depends only on the elements of D. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "[DRVW] Deshpande, Amit and Rademacher, Luis and Vempala, Santosh and Wang, Grant - Matrix Approximation and Projective Clustering via Volume Sampling 2006\n",
    "\n",
    "[BoDr] Boutsidis, Christos and Drineas, Petros  - Deterministic and randomized column selection algorithms for matrices 2014\n",
    "\n",
    "[] INDERJIT S. DHILLON , ROBERT W. HEATH JR., MA ́TYA ́S A. SUSTIK, AND\n",
    "JOEL A. TROPP - GENERALIZED FINITE ALGORITHMS FOR CONSTRUCTING HERMITIAN MATRICES\n",
    "WITH PRESCRIBED DIAGONAL AND SPECTRUM 2005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I- Generating a cloud of points with geometric constraints\n",
    "In this simulation we will enforce some structure on the matrix V for two values of the matrix D. While the matrix U will be choosen randomly.  \n",
    "We want to investigate the influence of the profile of the norms of the V_k rows: the k-leverage scores. For this purpose we use an algorithm proposed in the article []: this algorithm outputs a ( dxk)  matrix Q with orthonormal columns and a prescribed profile of the norms of the rows. If we consider the Gram matrix H= QQ^{T}, this boils down to enforce the diagonal of H while keeping its spectrum containing k ones and d-k zeros.  \n",
    "The algorithm proceed as following:\n",
    "* Initialization of the matrix Q by the rectangular identity\n",
    "* Apply a Givens Rotation (of dimension d) to the matrix Q: this step will enforce the norm of a row every iteration\n",
    "* Outputs the resulting matrix when all the rows norms are enforced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from scipy.stats import binom\n",
    "import scipy.special\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import display, HTML\n",
    "from FrameBuilder.eigenstepsbuilder import *\n",
    "from decimal import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-1- Givens Rotations generators\n",
    "These functions generate a Givens rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_func(q_i,q_j,q_ij,l_i,l_j): \n",
    "    # t in section 3.1 Dhillon (2005) \n",
    "    delta = np.power(q_ij,2)-(q_i-l_i)*(q_j-l_i)\n",
    "    if delta<0:\n",
    "        print(delta)\n",
    "        print(\"error sqrt\")\n",
    "    t = q_ij - np.sqrt(delta) \n",
    "    t = t/(q_j-l_i)\n",
    "    return t\n",
    "     \n",
    "def G_func(i,j,q_i,q_j,q_ij,l_i,l_j,N): \n",
    "    # Gitens Rotation \n",
    "    G=np.eye(N) \n",
    "    t = t_func(q_i,q_j,q_ij,l_i,l_j)\n",
    "    c = 1/(np.sqrt(np.power(t,2)+1))\n",
    "    s = t*c\n",
    "    G[i,i]=c\n",
    "    G[i,j]=s \n",
    "    G[j,i]= -s\n",
    "    G[j,j]= c\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following function is an implementation of the algorithm [] figuring in the article [] to generate an orthogonal matrix with a prescribed profile of leverage scores.\n",
    "In fact this is a simplification of the algorithm ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Set_Generator:\n",
    "    def __init__(self, N, d, nu, Sigma):\n",
    "        self.N = N\n",
    "        self.d = d\n",
    "        self.nu = nu\n",
    "        self.Sigma = Sigma\n",
    "        self.mean = np.zeros(d)\n",
    "        \n",
    "    def multivariate_t_rvs(self):\n",
    "        x = np.random.chisquare(self.nu, self.N)/self.nu\n",
    "        z = np.random.multivariate_normal(self.mean,self.Sigma,(self.N,))\n",
    "        return self.mean + z/np.sqrt(x)[:,None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_orthonormal_matrix_with_leverage_scores_ES(N,d,lv_scores_vector,versions_number,nn_cardinal_list):\n",
    "\n",
    "    lambda_vector = np.zeros((N))\n",
    "    lambda_vector[0:d] = np.ones((d))\n",
    "\n",
    "    #mu_vector = np.linspace(1, 0.1, num=N)\n",
    "    #sum_mu_vector = np.sum(mu_vector)\n",
    "    #mu_vector = d/sum_mu_vector*mu_vector\n",
    "    Q = np.zeros((N,d))\n",
    "    previous_Q = np.zeros((versions_number+1,N,d))\n",
    "    #mu_vector = d/N*np.ones((N,1))\n",
    "    E = np.zeros((N,N)) #(d,N)\n",
    "    counter = 0\n",
    "    for j in nn_cardinal_list:\n",
    "        print(\"counter\")\n",
    "        print(counter)\n",
    "        mu_vector = generate_leverage_scores_vector_with_dirichlet(N,d,j)\n",
    "        print(np.sum(mu_vector))\n",
    "        print(mu_vector)\n",
    "        E_test = get_eigensteps_random(mu_vector,lambda_vector,N,d)\n",
    "        E_ = np.zeros((d,N+1))\n",
    "        for i in range(d):\n",
    "            E_[i,1:N+1] = E_test[i,:] \n",
    "        F_test = get_F(d,N,np.asmatrix(E_),mu_vector)\n",
    "        previous_Q[counter,:,:] = np.transpose(F_test)\n",
    "        Q = np.transpose(F_test)\n",
    "        counter = counter +1\n",
    "    return Q,previous_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter\n",
      "0\n",
      "2.0\n",
      "[0.61426, 0.18506, 0.17432, 0.1239, 0.10059, 0.099121, 0.09021, 0.085205, 0.085083, 0.069824, 0.066772, 0.065308, 0.064514, 0.064392, 0.037811, 0.025101, 0.019394, 0.018295, 0.0084991, 0.0021992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "counter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abelhadj/Desktop/FrameBuilder/FrameBuilder/eigenstepsbuilder.py:137: RuntimeWarning: invalid value encountered in sqrt\n",
      "  v_n[v_n_index] = np.sqrt(-np.prod(nom_v_n)/np.prod(denom_v_n))\n",
      "/Users/abelhadj/Desktop/FrameBuilder/FrameBuilder/eigenstepsbuilder.py:144: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  w_n[w_n_index] = np.sqrt(np.prod(nom_w_n)/np.prod(denom_w_n))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2.0\n",
      "[0.80859, 0.33569, 0.2688, 0.22998, 0.12646, 0.097595, 0.083008, 0.040588, 0.0085983, 0.0005002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "counter\n",
      "2\n",
      "2.0\n",
      "[0.57861, 0.37891, 0.323, 0.22937, 0.20776, 0.1217, 0.076172, 0.040497, 0.028, 0.016098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "Q,previous_Q = generate_orthonormal_matrix_with_leverage_scores_ES(100,2,[],3,[20,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.64216002,  0.        ],\n",
       "        [-0.18802007, -0.53902147],\n",
       "        [ 0.21753891,  0.50028943],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.92100946,  0.        ],\n",
       "        [ 0.07242599, -0.72642915],\n",
       "        [-0.15342414, -0.60459993],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.84549494,  0.        ],\n",
       "        [-0.17900511,  0.67818971],\n",
       "        [ 0.39118836,  0.38375836],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ]],\n",
       "\n",
       "       [[ 1.03134402,  0.        ],\n",
       "        [ 0.        ,  0.5599646 ],\n",
       "        [ 0.        ,  0.49710795],\n",
       "        ..., \n",
       "        [        nan,         nan],\n",
       "        [        nan,         nan],\n",
       "        [        nan,         nan]],\n",
       "\n",
       "       [[ 0.80850705,  0.        ],\n",
       "        [ 0.21040674,  0.71491349],\n",
       "        [ 0.41763575, -0.37430361],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_leverage_scores_vector_with_dirichlet(d,k,nn_cardinal):\n",
    "    getcontext().prec = 3\n",
    "    mu_vector = np.float16(np.zeros((d,)))\n",
    "    mu_vector_2 = np.float16(np.zeros((d,)))\n",
    "    not_bounded = 1\n",
    "    while(not_bounded == 1):\n",
    "        mu_vector[0:nn_cardinal] = (k*np.random.dirichlet([1]*nn_cardinal, 1))[0]\n",
    "        mu_vector = np.flip(np.sort(mu_vector),axis = 0)\n",
    "        if max(mu_vector)<=1:\n",
    "            not_bounded = 0\n",
    "    for i in range(nn_cardinal):\n",
    "        mu_vector_2[i] = round(mu_vector[i],4)\n",
    "    mu_vector_2 = k*mu_vector_2/np.sum(mu_vector_2)\n",
    "    return list(mu_vector_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66357, 0.54834, 0.36377, 0.22363, 0.18567, 0.015099, 0.0, 0.0, 0.0, 0.0]\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "l = generate_leverage_scores_vector_with_dirichlet(10,2,6)\n",
    "print(l)\n",
    "print(np.sum(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_orthonormal_matrix_with_leverage_scores(N,d,lv_scores_vector,versions_number,mode):\n",
    "    #Transforming an idendity matrix to an orthogonal matrix with prescribed lengths\n",
    "    Q = np.zeros((N,d))\n",
    "    previous_Q = np.zeros((versions_number+1,N,d))\n",
    "    versionning_period = (int)(N/versions_number)\n",
    "    if mode == 'identity':\n",
    "        for _ in range(0,d):\n",
    "            Q[_,_] = 1\n",
    "    if mode == 'spread':\n",
    "        nu = 1\n",
    "        Sigma = np.diag(np.ones(d))\n",
    "        mean = np.zeros(d)\n",
    "        x = np.random.chisquare(nu, N)/nu\n",
    "        z = np.random.multivariate_normal(mean,Sigma,(N,))\n",
    "        dataset = mean + z/np.sqrt(x)[:,None] \n",
    "        [Q,_,_] = np.linalg.svd(dataset,full_matrices=False)\n",
    "        print(np.shape(Q))\n",
    "    I_sorting =  list(reversed(np.argsort(lv_scores_vector)))\n",
    "    \n",
    "    lv_scores_vector = np.asarray(list(reversed(np.sort(lv_scores_vector))))\n",
    "    initial_lv_scores_vector = np.diag(np.dot(Q,Q.T))\n",
    "    I_initial_sorting = list(reversed(np.argsort(initial_lv_scores_vector)))\n",
    "    initial_lv_scores_vector = np.asarray(list(reversed(np.sort(np.diag(np.dot(Q,Q.T))))))\n",
    "    #initial_lv_scores_vector = \n",
    "\n",
    "    Q[I_initial_sorting,:] = Q\n",
    "    print(lv_scores_vector)\n",
    "    print(initial_lv_scores_vector)\n",
    "    delta_lv_scores_vector = lv_scores_vector - initial_lv_scores_vector\n",
    "    print(delta_lv_scores_vector)\n",
    "    min_index = next((i for i, x in enumerate(delta_lv_scores_vector) if x>0), None)\n",
    "    i = min_index-1\n",
    "    j = min_index\n",
    "    print(i)\n",
    "    print(j)\n",
    "    #if mode == 'identity':\n",
    "    #    i = d-1\n",
    "    #    j = d\n",
    "    #if mode == 'spread':\n",
    "    #    i = d-2\n",
    "    #    j = d-1\n",
    "    v_counter =0\n",
    "    for t in range(N-1):\n",
    "        #print(i)\n",
    "        #print(j)\n",
    "        delta_i = np.abs(lv_scores_vector[i] - np.power(np.linalg.norm(Q[i,:]),2))\n",
    "        delta_j = np.abs(lv_scores_vector[j] - np.power(np.linalg.norm(Q[j,:]),2))\n",
    "        q_i = np.power(np.linalg.norm(Q[i,:]),2)\n",
    "        q_j = np.power(np.linalg.norm(Q[j,:]),2)\n",
    "        q_ij = np.dot(Q[i,:],Q[j,:].T)\n",
    "        l_i = lv_scores_vector[i]\n",
    "        l_j = lv_scores_vector[j]\n",
    "        G = np.eye(N)\n",
    "        if t%versionning_period ==0:\n",
    "            previous_Q[v_counter,:,:] = Q\n",
    "            v_counter = v_counter +1\n",
    "        if delta_i <= delta_j:\n",
    "            l_k = q_i + q_j -l_i\n",
    "            G = G_func(i,j,q_i,q_j,q_ij,l_i,l_k,N)\n",
    "            Q = np.dot(G,Q)\n",
    "            i = i-1\n",
    "        else:\n",
    "            l_k = q_i + q_j -l_j\n",
    "            G = G_func(i,j,q_j,q_i,q_ij,l_j,l_k,N)\n",
    "            Q = np.dot(G,Q)\n",
    "            j = j+1\n",
    "    previous_Q[versions_number,:,:] = Q\n",
    "    return Q,previous_Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function allows to estimate the leverage scores for an orthogonal matrix Q: the function calculates the diagonoal of the matrix $$Q Q^{T}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_leverage_scores_from_orthogonal_matrix(Q):\n",
    "    [N,_] = np.shape(Q)\n",
    "    lv_scores_vector = np.zeros((N,1))\n",
    "    lv_scores_vector = np.diag(np.dot(Q,np.transpose(Q)))\n",
    "    lv_scores_vector = np.asarray(list(reversed(np.sort(lv_scores_vector))))\n",
    "    return lv_scores_vector\n",
    "def estimate_sum_first_k_leverage_scores(Q,k):\n",
    "    lv_scores_vector = estimate_leverage_scores_from_orthogonal_matrix(Q)\n",
    "    res = np.sum(lv_scores_vector[0:k])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## I-2- Extending the orthogonal matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the task of low rank approximation, we have seen that only the information contained in the first right k eigenvectors of the matrix X are relevant. In the previous step we build only the first right k eigenvectors but we still need to complete these orthogonal matrices with d-k columns. We proceed as following:\n",
    "Generate a random vector (Nx1) using independent standard gaussian variables,\n",
    "Project this vector in the orthogonal of the span of Q\n",
    "Normalize the obtained vector after the projection\n",
    "Extend the matrix Q\n",
    "Note that this procedure is not the unique way to extend the matrix Q to an orthogonal (Nxd) matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_orthogonal_matrix(Q,d_target):\n",
    "    [N,d] = np.shape(Q)\n",
    "    Q_target = np.zeros((N,d))\n",
    "    Q_target = Q\n",
    "    delta = d_target - d\n",
    "    for t in range(delta):\n",
    "        Q_test = np.random.normal(0, 1, N)\n",
    "        for _ in range(d):\n",
    "            Q_test = Q_test - np.dot(Q_test,Q[:,_])*Q[:,_]\n",
    "        Q_test = Q_test/np.linalg.norm(Q_test)\n",
    "        Q_test = Q_test.reshape(N,1)\n",
    "        Q_target = np.append(Q_target,Q_test,1)\n",
    "    return Q_target\n",
    "\n",
    "#extended_Q = extend_orthogonal_matrix(Q,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I-3 - Constructing a dataset for every extended orthogonal matrix \n",
    "The previous step allow us to build (N x d) orthogonal matrices such that the extracted (N x k) matrix have a prescribed profile of leverage scores.\n",
    "Now we construct a cloud of point by assigning a covariance matrix D and a matrix V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contruct_dataset_from_orthogonal_matrix(multi_Q,N,target_d,cov,mean,versions_number):\n",
    "    multi_X = np.zeros((versions_number+1,N,real_dim))\n",
    "    for t in range(versions_number+1):\n",
    "        test_X = np.random.multivariate_normal(mean, cov, N)\n",
    "        [U,_,_] = np.linalg.svd(test_X, full_matrices=False)\n",
    "        Q_test = extend_orthogonal_matrix(multi_Q[t,:,:],target_d)\n",
    "        multi_X[t,:,:] = np.dot(np.dot(Q_test,cov),U.T).T\n",
    "    return multi_X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II- Volume sampling vs Projection DPP for low rank approximation\n",
    "These functions allow to quantify the approximation error:\n",
    "* approximation_error_function_fro calculate the ratio of the approximation error of a subset of columns to the optimal approximatione error given by the first k left eigenvectors of the matrix X\n",
    "* expected_approximation_error_for_sampling_scheme calculate the expected value of the ratio of the approximatione error under some sampling distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximation_error_function_fro(Sigma,k,X,X_S):\n",
    "    ## Sigma is the spectrum of the matrix X: we need to calculate the optimal approximation error given by the PCA\n",
    "    ## k is the rank of the approximation\n",
    "    ## X is the initial matrix\n",
    "    ## X_S is the subset of columns of the matrix X for witch we calculate the approximation error ratio\n",
    "    d = list(Sigma.shape)[0] # the dimension of the matrix X\n",
    "    Sigma = np.multiply(Sigma,Sigma)  # Sigma power 2 -> we are intersted in the approximation error square\n",
    "    sigma_S_temp = np.linalg.inv(np.dot(X_S.T,X_S))  # just a temporary matrix to construct the projection matrix\n",
    "    projection_S = np.dot(np.dot(X_S,sigma_S_temp),X_S.T) # the projection matrix P_S\n",
    "    res_X = X - np.dot(projection_S,X) # The projection of the matrix X in the orthogonal of S\n",
    "    approximation_error_ratio = np.power(np.linalg.norm(res_X,'fro'),2)/np.sum(Sigma[k:d])\n",
    "    # Calculate the apparoximation error ratio\n",
    "    return approximation_error_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximation_error_function_spectral(Sigma,k,X,X_S):\n",
    "    ## Sigma is the spectrum of the matrix X: we need to calculate the optimal approximation error given by the PCA\n",
    "    ## k is the rank of the approximation\n",
    "    ## X is the initial matrix\n",
    "    ## X_S is the subset of columns of the matrix X for witch we calculate the approximation error ratio\n",
    "    d = list(Sigma.shape)[0] # the dimension of the matrix X\n",
    "    Sigma = np.multiply(Sigma,Sigma)  # Sigma power 2 -> we are intersted in the approximation error square\n",
    "    sigma_S_temp = np.linalg.inv(np.dot(X_S.T,X_S))  # just a temporary matrix to construct the projection matrix\n",
    "    projection_S = np.dot(np.dot(X_S,sigma_S_temp),X_S.T) # the projection matrix P_S\n",
    "    res_X = X - np.dot(projection_S,X) # The projection of the matrix X in the orthogonal of S\n",
    "    approximation_error_ratio = np.power(np.linalg.norm(res_X,ord = 2),2)/np.sum(Sigma[k:k+1])\n",
    "    # Calculate the apparoximation error ratio\n",
    "    return approximation_error_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upper_bound_error_function_for_projection_DPP(k,X,X_S):\n",
    "    ## Sigma is the spectrum of the matrix X: we need to calculate the optimal approximation error given by the PCA\n",
    "    ## k is the rank of the approximation\n",
    "    ## X is the initial matrix\n",
    "    ## X_S is the subset of columns of the matrix X for witch we calculate the approximation error ratio\n",
    "    _,sigma_S_temp,_ = np.linalg.svd(X_S, full_matrices=False)  # just a temporary matrix to construct the projection matrix\n",
    "    trunc_product = np.power(np.prod(sigma_S_temp[0:k-1]),2)\n",
    "    if np.power(np.prod(sigma_S_temp[0:k]),2) == 0:\n",
    "        trunc_product = 0\n",
    "    # Calculate the apparoximation error ratio\n",
    "    return trunc_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tight_upper_bound_error_function_fro(k,X,X_S,V_k,V_k_S):\n",
    "    ## Sigma is the spectrum of the matrix X: we need to calculate the optimal approximation error given by the PCA\n",
    "    ## k is the rank of the approximation\n",
    "    ## X is the initial matrix\n",
    "    ## X_S is the subset of columns of the matrix X for witch we calculate the approximation error ratio\n",
    "    _,Sigma,_ = np.linalg.svd(X, full_matrices=False)\n",
    "    d = list(Sigma.shape)[0]\n",
    "    Sigma = np.multiply(Sigma,Sigma)\n",
    "    if np.linalg.matrix_rank(V_k_S,0.000001) == k:\n",
    "        temp_T = np.dot(np.linalg.inv(V_k_S),V_k)\n",
    "        temp_matrix = X - np.dot(X_S,temp_T)\n",
    "    \n",
    "        return np.power(np.linalg.norm(temp_matrix,'fro'),2)/np.sum(Sigma[k:d])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_the_matrix_sum_T_S(k,d,V_k,V_d_k):\n",
    "    ## Sigma is the spectrum of the matrix X: we need to calculate the optimal approximation error given by the PCA\n",
    "    ## k is the rank of the approximation\n",
    "    ## X is the initial matrix\n",
    "    ## X_S is the subset of columns of the matrix X for witch we calculate the approximation error ratio\n",
    "    #Sigma = np.multiply(Sigma,Sigma)\n",
    "    #matrices_array = [ np.dot(V_d_k[:,list(comb)],np.dot(np.dot(np.linalg.inv(V_k[:,list(comb)]),np.linalg.inv(V_k[:,list(comb)]))),np.transpose(V_d_k[:,list(comb)])) for comb in combinations(range(d),k) if np.linalg.matrix_rank(V_k[:,list(comb)],0.000001) == k]\n",
    "    T = np.zeros((d-k,d-k))\n",
    "    for comb in combinations(range(d),k):\n",
    "        if np.linalg.matrix_rank(V_k[:,list(comb)],0.0000000001) == k: \n",
    "            V_k_S_inv = np.linalg.inv(V_k[:,list(comb)])\n",
    "            V_d_k_S = V_d_k[:,list(comb)]\n",
    "            V_k_S_inv_2 = np.transpose(np.dot(V_k_S_inv,np.transpose(V_k_S_inv)))\n",
    "            #T = np.dot(np.dot(np.dot(V_d_k_S,np.dot(V_k_S_inv,np.transpose(V_k_S_inv)))),np.transpose(V_d_k_S)) + T\n",
    "            T = np.power(np.linalg.det(V_k[:,list(comb)]),2)*np.dot(V_d_k_S,np.dot(V_k_S_inv_2,np.transpose(V_d_k_S))) +T\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tight_approximation_error_fro_for_sampling_scheme(X,U,k,N):\n",
    "    ## X is the matrix X :)\n",
    "    ## U is the matrix used in the sampling: we sample propotional to the volume of UU^{T}_{S,S}: \n",
    "    ## we are not sampling but we need the weigth to estimate the expected error\n",
    "    ## k is the rank of the approximation\n",
    "    ## N is the number of columns (to be changed to avoid confusion with the number of points)\n",
    "    _,Sigma,V = np.linalg.svd(X, full_matrices=False)\n",
    "    V_k = V[0:k,:]\n",
    "    ## Estimating the spectrum of X -> needed in approximation_error_function_fro\n",
    "    volumes_array = [np.abs(np.linalg.det(np.dot(U[:,list(comb)].T,U[:,list(comb)]))) for comb in combinations(range(N),k)]\n",
    "    ## Construct the array of weights: the volumes of UU^{T}_{S,S}\n",
    "    volumes_array_sum = np.sum(volumes_array)\n",
    "    ## The normalization constant\n",
    "    volumes_array = volumes_array/volumes_array_sum\n",
    "    ## The weigths normalized\n",
    "    approximation_error_array = [tight_upper_bound_error_function_fro(k,X,X[:,list(comb)],V_k,V_k[:,list(comb)]) for comb in combinations(range(N),k)]\n",
    "    ## Calculating the approximation error for every k-tuple\n",
    "    expected_value = np.dot(approximation_error_array,volumes_array)\n",
    "    ## The expected value of the approximatione error is just the dot product of the two arrays above\n",
    "    return expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expected_approximation_error_fro_for_sampling_scheme(X,U,k,N):\n",
    "    ## X is the matrix X :)\n",
    "    ## U is the matrix used in the sampling: we sample propotional to the volume of UU^{T}_{S,S}: \n",
    "    ## we are not sampling but we need the weigth to estimate the expected error\n",
    "    ## k is the rank of the approximation\n",
    "    ## N is the number of columns (to be changed to avoid confusion with the number of points)\n",
    "    _,Sigma,_ = np.linalg.svd(X, full_matrices=False)\n",
    "    ## Estimating the spectrum of X -> needed in approximation_error_function_fro\n",
    "    volumes_array = [np.abs(np.linalg.det(np.dot(U[:,list(comb)].T,U[:,list(comb)]))) for comb in combinations(range(N),k)]\n",
    "    ## Construct the array of weights: the volumes of UU^{T}_{S,S}\n",
    "    volumes_array_sum = np.sum(volumes_array)\n",
    "    ## The normalization constant\n",
    "    volumes_array = volumes_array/volumes_array_sum\n",
    "    ## The weigths normalized\n",
    "    approximation_error_array = [approximation_error_function_fro(Sigma,k,X,X[:,list(comb)]) for comb in combinations(range(N),k)]\n",
    "    ## Calculating the approximation error for every k-tuple\n",
    "    expected_value = np.dot(approximation_error_array,volumes_array)\n",
    "    ## The expected value of the approximatione error is just the dot product of the two arrays above\n",
    "    return expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expected_approximation_error_spectral_for_sampling_scheme(X,U,k,N):\n",
    "    ## X is the matrix X :)\n",
    "    ## U is the matrix used in the sampling: we sample propotional to the volume of UU^{T}_{S,S}: \n",
    "    ## we are not sampling but we need the weigth to estimate the expected error\n",
    "    ## k is the rank of the approximation\n",
    "    ## N is the number of columns (to be changed to avoid confusion with the number of points)\n",
    "    _,Sigma,_ = np.linalg.svd(X, full_matrices=False)\n",
    "    ## Estimating the spectrum of X -> needed in approximation_error_function_fro\n",
    "    volumes_array = [np.abs(np.linalg.det(np.dot(U[:,list(comb)].T,U[:,list(comb)]))) for comb in combinations(range(N),k)]\n",
    "    ## Construct the array of weights: the volumes of UU^{T}_{S,S}\n",
    "    volumes_array_sum = np.sum(volumes_array)\n",
    "    ## The normalization constant\n",
    "    volumes_array = volumes_array/volumes_array_sum\n",
    "    ## The weigths normalized\n",
    "    approximation_error_array = [approximation_error_function_spectral(Sigma,k,X,X[:,list(comb)]) for comb in combinations(range(N),k)]\n",
    "    ## Calculating the approximation error for every k-tuple\n",
    "    expected_value = np.dot(approximation_error_array,volumes_array)\n",
    "    ## The expected value of the approximatione error is just the dot product of the two arrays above\n",
    "    return expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expected_upper_bound_for_projection_DPP(X,U,k,N):\n",
    "    ## X is the matrix X :)\n",
    "    ## U is the matrix used in the sampling: we sample propotional to the volume of UU^{T}_{S,S}: \n",
    "    ## we are not sampling but we need the weigth to estimate the expected error\n",
    "    ## k is the rank of the approximation\n",
    "    ## N is the number of columns (to be changed to avoid confusion with the number of points)\n",
    "\n",
    "    approximation_error_array = [upper_bound_error_function_for_projection_DPP(k,X,U[:,list(comb)]) for comb in combinations(range(N),k)]\n",
    "    ## Calculating the approximation error for every k-tuple\n",
    "    \n",
    "    ## The expected value of the approximatione error is just the dot product of the two arrays above\n",
    "    #return expected_value\n",
    "    return np.sum(approximation_error_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## III - Numerical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we use the functions developed previously to investigate the influence of two parameters: the spectrum of X and the k-leverage scores.  \n",
    "For this purpose, we assemble these functionalities in a class allowing fast numerical experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Numrerical_Analysis_DPP: \n",
    "    def __init__(self,N,real_dim,r,k,versions_number,mean,cov,lv_scores):\n",
    "        self.N = N\n",
    "        self.real_dim = real_dim\n",
    "        self.r = r\n",
    "        self.k = k\n",
    "        self.versions_number = versions_number\n",
    "        self.mean = mean\n",
    "        self.cov = cov\n",
    "        self.lv_scores = lv_scores\n",
    "        self.Q = np.zeros((real_dim,k))\n",
    "        self.multi_Q = np.zeros((self.versions_number+1,real_dim,k))\n",
    "        self.X = np.zeros((N,real_dim))\n",
    "        self.multi_X = np.zeros((self.versions_number+1,N,real_dim))\n",
    "        [self.Q,self.multi_Q] = generate_orthonormal_matrix_with_leverage_scores(real_dim,k,lv_scores,versions_number,'identity')\n",
    "        self.multi_X = contruct_dataset_from_orthogonal_matrix(self.multi_Q,self.N,self.real_dim,self.cov,self.mean,self.versions_number)\n",
    "    def contruct_dataset_from_orthogonal_matrix_4(self,multi_Q,N,target_d,cov,mean,versions_number):\n",
    "        test_multi_X = np.zeros((self.versions_number+1,N,real_dim))\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = np.random.multivariate_normal(mean, cov, N)\n",
    "            [U,_,_] = np.linalg.svd(test_X, full_matrices=False)\n",
    "            Q_test = extend_orthogonal_matrix(self.multi_Q[t,:,:],target_d)\n",
    "            test_multi_X[t,:,:] = np.dot(np.dot(Q_test,cov),U.T).T\n",
    "        return test_multi_X\n",
    "    def get_expected_error_fro_for_volume_sampling(self):\n",
    "        ## Calculate the expected error ratio for the Volume Sampling distribution for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            res_list[t] = expected_approximation_error_fro_for_sampling_scheme(test_X,test_X,self.k,self.real_dim)\n",
    "        return res_list\n",
    "    def get_tight_upper_bound_error_fro_for_projection_DPP(self):\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            test_U = self.multi_Q[t,:,:].T\n",
    "            res_list[t] = tight_approximation_error_fro_for_sampling_scheme(test_X,test_U,self.k,self.real_dim)\n",
    "        return res_list\n",
    "    def get_max_diag_sum_T_matrices(self):\n",
    "        res_list = np.zeros((self.versions_number+1))\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            _,_,test_V = np.linalg.svd(test_X, full_matrices=False)\n",
    "            test_V_k = test_V[0:self.k,:]\n",
    "            test_V_d_k = test_V[self.k:self.real_dim,:]\n",
    "            res_list[t] = 1+np.max(np.diag(get_the_matrix_sum_T_S(self.k,self.real_dim,test_V_k,test_V_d_k)))\n",
    "        return res_list\n",
    "    def get_max_spectrum_sum_T_matrices(self):\n",
    "        res_list = np.zeros((self.versions_number+1))\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            _,_,test_V = np.linalg.svd(test_X, full_matrices=False)\n",
    "            test_V_k = test_V[0:self.k,:]\n",
    "            test_V_d_k = test_V[self.k:self.real_dim,:]\n",
    "            res_list[t] = 1+np.max(np.diag(get_the_matrix_sum_T_S(self.k,self.real_dim,test_V_k,test_V_d_k)))\n",
    "        return res_list\n",
    "    def get_expected_error_fro_for_projection_DPP(self):\n",
    "        ## Calculate the expected error ratio for the Projection DPP distribution for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            test_U = self.multi_Q[t,:,:].T\n",
    "            res_list[t] = expected_approximation_error_fro_for_sampling_scheme(test_X,test_U,self.k,self.real_dim)\n",
    "        return res_list   \n",
    "    def get_expected_error_spectral_for_volume_sampling(self):\n",
    "        ## Calculate the expected error ratio for the Volume Sampling distribution for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            res_list[t] = expected_approximation_error_spectral_for_sampling_scheme(test_X,test_X,self.k,self.real_dim)\n",
    "        return res_list\n",
    "    def get_expected_error_spectral_for_projection_DPP(self):\n",
    "        ## Calculate the expected error ratio for the Projection DPP distribution for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            test_U = self.multi_Q[t,:,:].T\n",
    "            res_list[t] = expected_approximation_error_spectral_for_sampling_scheme(test_X,test_U,self.k,self.real_dim)\n",
    "        return res_list  \n",
    "    def get_upper_bound_error_for_projection_DPP(self):\n",
    "        ## Calculate the expected error ratio for the Projection DPP distribution for every dataset\n",
    "        #res_list = np.zeros(self.versions_number+1)\n",
    "        res_list = []\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            test_U = self.multi_Q[t,:,:].T\n",
    "            #res_list[t] = expected_upper_bound_for_projection_DPP(test_X,test_U,self.k,self.real_dim)\n",
    "            res_list.append( expected_upper_bound_for_projection_DPP(test_X,test_U,self.k,self.real_dim))\n",
    "        return res_list  \n",
    "    def get_error_fro_for_deterministic_selection(self):\n",
    "        ## Calculate the error ratio for the k-tuple selected by the deterministic algorithm for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            test_U = self.multi_Q[t,:,:].T\n",
    "            lv_scores_vector = np.diag(np.dot(np.transpose(test_U),test_U))\n",
    "            test_I_k = list(np.argsort(lv_scores_vector)[self.real_dim-self.k:self.real_dim])\n",
    "            _,test_Sigma,_ = np.linalg.svd(test_X, full_matrices=False)\n",
    "            res_list[t] = approximation_error_function_fro(test_Sigma,self.k,test_X,test_X[:,test_I_k])\n",
    "            #res_list.append(test_I_k)\n",
    "        return res_list   \n",
    "    def get_error_spectral_for_deterministic_selection(self):\n",
    "        ## Calculate the error ratio for the k-tuple selected by the deterministic algorithm for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            test_X = self.multi_X[t,:,:]\n",
    "            test_U = self.multi_Q[t,:,:].T\n",
    "            lv_scores_vector = np.diag(np.dot(np.transpose(test_U),test_U))\n",
    "            test_I_k = list(np.argsort(lv_scores_vector)[self.real_dim-self.k:self.real_dim])\n",
    "            _,test_Sigma,_ = np.linalg.svd(test_X, full_matrices=False)\n",
    "            res_list[t] = approximation_error_function_spectral(test_Sigma,self.k,test_X,test_X[:,test_I_k])\n",
    "            #res_list.append(test_I_k)\n",
    "        return res_list \n",
    "    def get_sum_k_leverage_scores(self):\n",
    "        ## A function that calculate the k-sum: the sum of the first k k-leverage scores. It is a measure of the concentration of V_k\n",
    "        ## This is done for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            res_list[t] = estimate_sum_first_k_leverage_scores(self.multi_Q[t,:,:],self.k)\n",
    "        return res_list\n",
    "    def get_deterministic_upper_bound(self):\n",
    "        ## A function that calculate the theoretical upper bound for the deterministic algorithm for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        for t in range(self.versions_number+1):\n",
    "            res_list[t] = 1/(1+estimate_sum_first_k_leverage_scores(self.multi_Q[t,:,:],self.k)-self.k)\n",
    "        return res_list\n",
    "    def get_alpha_sum_k_leverage_scores(self,alpha):\n",
    "        ## A function that calculate the theoretical upper bound for the deterministic algorithm for every dataset\n",
    "        res_list = np.zeros(self.versions_number+1)\n",
    "        #k_l = self.get_sum_k_leverage_scores()\n",
    "        for t in range(self.versions_number+1):\n",
    "            k_l = estimate_leverage_scores_from_orthogonal_matrix(self.multi_Q[t,:,:])[0:k]\n",
    "            func_k = np.power(np.linspace(1, k, num=k),alpha)\n",
    "            res_list[t] = np.dot(func_k,k_l)\n",
    "        return res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III- 0 Parameters of the simultations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The dimensions of the design matrix X\n",
    "N = 100       # The number of observations in the dataset\n",
    "real_dim = 20 # The dimension of the dataset\n",
    "## The low rank paramters\n",
    "k = 4         # The rank of the low rank approximation \n",
    "## The covariance matrix parameters\n",
    "r = 6         # Just a parameter to control the number of non trivial singular values in the covariance matrix\n",
    "mean = np.zeros((real_dim))    # The mean vector useful to generate U (X = UDV^T)\n",
    "cov_test = 0.1*np.ones((real_dim-r))  # The \"trivial\" singular values in the covariance matrix (there are real_dim-r)\n",
    "## The paramters of the matrix V\n",
    "versions_number = 5 # The number of orthogonal matrices (and therefor datasets) (-1) generated by the algorithm above\n",
    "lv_scores_vector = k/real_dim*np.ones(real_dim)  # The vector of leverage scores (the last one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III-1 The influence of the spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection we compare the Volume Sampling distribution to the projection DPP distribution and the deterministic algorithm of []  for different profiles of the spectrum with k-leverage scores profile fixed. In other words, if we note $$X = UDV^{T}$$ We keep V_{k} constant and we investigate the effect of D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III-1-1 The case of a non-projection spectrum\n",
    "We mean by a projection spectrum matrix, a matrix with equal the first k singular values.\n",
    "We observe that the two distributions are very similar.... \\todo{reword}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "  0.2  0.2  0.2  0.2  0.2]\n",
      "[ 1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "[-0.8 -0.8 -0.8 -0.8  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "  0.2  0.2  0.2  0.2  0.2]\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "cov_1 = np.diag(np.concatenate(([100,100,100,100,5,5],cov_test)))\n",
    "NAL_1 = Numrerical_Analysis_DPP(N,real_dim,r,k,versions_number,mean,cov_1,lv_scores_vector)\n",
    "\n",
    "\n",
    "projection_DPP_res_fro_1 = NAL_1.get_expected_error_fro_for_projection_DPP()\n",
    "volume_sampling_res_fro_1 = NAL_1.get_expected_error_fro_for_volume_sampling()\n",
    "deterministic_selection_res_fro_1 = NAL_1.get_error_fro_for_deterministic_selection()\n",
    "projection_DPP_res_spectral_1 = NAL_1.get_expected_error_spectral_for_projection_DPP()\n",
    "volume_sampling_res_spectral_1 = NAL_1.get_expected_error_spectral_for_volume_sampling()\n",
    "deterministic_selection_res_spectral_1 = NAL_1.get_error_spectral_for_deterministic_selection()\n",
    "\n",
    "upper_tight_bound_projection_DPP_res_fro_1 = NAL_1.get_tight_upper_bound_error_fro_for_projection_DPP()\n",
    "\n",
    "alpha_sum_res_1 = NAL_1.get_alpha_sum_k_leverage_scores(1)\n",
    "\n",
    "\n",
    "sum_U_res_1 = NAL_1.get_sum_k_leverage_scores()\n",
    "deterministic_upper_bound_res_1 = NAL_1.get_deterministic_upper_bound()\n",
    "\n",
    "expected_upper_bound_res_1 = NAL_1.get_upper_bound_error_for_projection_DPP()\n",
    "multi_Q_1 = NAL_1.multi_Q[1,:,:].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(k*(real_dim-k+1))\n",
    "sum_T_matrices =  NAL_1.get_sum_T_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7359363541812884"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_T_matrices[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_1 = pd.DataFrame(\n",
    "    {'k-sum (ratio)': sum_U_res_1/k,\n",
    "     'alpha k-sum': alpha_sum_res_1,\n",
    "     'Expected Upper Bound for Projection DPP': expected_upper_bound_res_1,\n",
    "     'Volume Sampling(Fro)': volume_sampling_res_fro_1,\n",
    "     'Projection DPP(Fro)': projection_DPP_res_fro_1,\n",
    "     'Very sharp approximation of Projection DPP(Fro)': upper_tight_bound_projection_DPP_res_fro_1,\n",
    "     '1+Largest eigenvalue of sum_T': sum_T_matrices,\n",
    "     'Deterministic Algorithm(Fro)': deterministic_selection_res_fro_1,\n",
    "     'Volume Sampling(Spectral)': volume_sampling_res_spectral_1,\n",
    "     'Projection DPP(Spectral)': projection_DPP_res_spectral_1,\n",
    "     'Deterministic Algorithm(Spectral)': deterministic_selection_res_spectral_1,\n",
    "     'Deterministic Upper Bound': deterministic_upper_bound_res_1\n",
    "    })\n",
    "pd_1 = pd_1[['k-sum (ratio)', 'alpha k-sum','Expected Upper Bound for Projection DPP','Volume Sampling(Fro)','Projection DPP(Fro)','Very sharp approximation of Projection DPP(Fro)','1+Largest eigenvalue of sum_T','Deterministic Algorithm(Fro)','Volume Sampling(Spectral)','Projection DPP(Spectral)','Deterministic Algorithm(Spectral)','Deterministic Upper Bound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-sum (ratio)</th>\n",
       "      <th>alpha k-sum</th>\n",
       "      <th>Expected Upper Bound for Projection DPP</th>\n",
       "      <th>Volume Sampling(Fro)</th>\n",
       "      <th>Projection DPP(Fro)</th>\n",
       "      <th>Very sharp approximation of Projection DPP(Fro)</th>\n",
       "      <th>1+Largest eigenvalue of sum_T</th>\n",
       "      <th>Deterministic Algorithm(Fro)</th>\n",
       "      <th>Volume Sampling(Spectral)</th>\n",
       "      <th>Projection DPP(Spectral)</th>\n",
       "      <th>Deterministic Algorithm(Spectral)</th>\n",
       "      <th>Deterministic Upper Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.926202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.803169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4.923115</td>\n",
       "      <td>1.136374</td>\n",
       "      <td>1.136871</td>\n",
       "      <td>1.663247</td>\n",
       "      <td>1.473758</td>\n",
       "      <td>6.653100</td>\n",
       "      <td>1.068493</td>\n",
       "      <td>1.286192</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.880</td>\n",
       "      <td>4.921685</td>\n",
       "      <td>1.551058</td>\n",
       "      <td>1.554745</td>\n",
       "      <td>1.825671</td>\n",
       "      <td>1.294846</td>\n",
       "      <td>6.336934</td>\n",
       "      <td>1.625205</td>\n",
       "      <td>1.322935</td>\n",
       "      <td>-2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>3.6</td>\n",
       "      <td>26.936</td>\n",
       "      <td>4.925579</td>\n",
       "      <td>1.699969</td>\n",
       "      <td>1.703821</td>\n",
       "      <td>2.226536</td>\n",
       "      <td>1.836078</td>\n",
       "      <td>7.423669</td>\n",
       "      <td>1.861901</td>\n",
       "      <td>2.355279</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.35</td>\n",
       "      <td>2.6</td>\n",
       "      <td>36.256</td>\n",
       "      <td>4.926191</td>\n",
       "      <td>1.841557</td>\n",
       "      <td>1.847162</td>\n",
       "      <td>2.555151</td>\n",
       "      <td>1.112807</td>\n",
       "      <td>8.353569</td>\n",
       "      <td>2.341118</td>\n",
       "      <td>1.195264</td>\n",
       "      <td>-0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.296</td>\n",
       "      <td>4.926193</td>\n",
       "      <td>1.993425</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.455843</td>\n",
       "      <td>1.417632</td>\n",
       "      <td>8.202907</td>\n",
       "      <td>2.472186</td>\n",
       "      <td>1.734757</td>\n",
       "      <td>-0.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k-sum (ratio)  alpha k-sum  Expected Upper Bound for Projection DPP  \\\n",
       "0           1.00         10.0                                    1.000   \n",
       "1           0.80          6.8                                    5.000   \n",
       "2           0.65          5.0                                   16.880   \n",
       "3           0.50          3.6                                   26.936   \n",
       "4           0.35          2.6                                   36.256   \n",
       "5           0.20          2.0                                   44.296   \n",
       "\n",
       "   Volume Sampling(Fro)  Projection DPP(Fro)  \\\n",
       "0              4.926202             1.000000   \n",
       "1              4.923115             1.136374   \n",
       "2              4.921685             1.551058   \n",
       "3              4.925579             1.699969   \n",
       "4              4.926191             1.841557   \n",
       "5              4.926193             1.993425   \n",
       "\n",
       "   Very sharp approximation of Projection DPP(Fro)  \\\n",
       "0                                         1.000000   \n",
       "1                                         1.136871   \n",
       "2                                         1.554745   \n",
       "3                                         1.703821   \n",
       "4                                         1.847162   \n",
       "5                                         2.000000   \n",
       "\n",
       "   1+Largest eigenvalue of sum_T  Deterministic Algorithm(Fro)  \\\n",
       "0                       1.000000                      1.000000   \n",
       "1                       1.663247                      1.473758   \n",
       "2                       1.825671                      1.294846   \n",
       "3                       2.226536                      1.836078   \n",
       "4                       2.555151                      1.112807   \n",
       "5                       2.455843                      1.417632   \n",
       "\n",
       "   Volume Sampling(Spectral)  Projection DPP(Spectral)  \\\n",
       "0                   8.803169                  1.000000   \n",
       "1                   6.653100                  1.068493   \n",
       "2                   6.336934                  1.625205   \n",
       "3                   7.423669                  1.861901   \n",
       "4                   8.353569                  2.341118   \n",
       "5                   8.202907                  2.472186   \n",
       "\n",
       "   Deterministic Algorithm(Spectral)  Deterministic Upper Bound  \n",
       "0                           1.000000                   1.000000  \n",
       "1                           1.286192                   5.000000  \n",
       "2                           1.322935                  -2.500000  \n",
       "3                           2.355279                  -1.000000  \n",
       "4                           1.195264                  -0.625000  \n",
       "5                           1.734757                  -0.454545  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "* The expected error is always smaller under the Projection DPP distribution compared to the Volume Sampling distribution.\n",
    "* The expected error for the Volume Sampling distribution is constant for a contant D\n",
    "* However the expected error for the Projection DPP distribution depends on the k-sum\n",
    "* For X_0 and X_1, the profile of the k-leverage scores are highly concentrated (k-sum > k-1) thus epsilon is smaller than 1, in this regime the determinstic algorithm have the lower approximation error and it performs better than expected (the theoretical bound is 1/(1-epsilon).\n",
    "* However, for the other datasets, the (k-sum < k-1) thus epsilon >1 and the deterministic algorithm have no guarantee in this regime: we observe that the approximation error for the deterministic algorithm can be very high in this regime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall:\n",
    "We recall here some geometrical properties of the matrices $$X_i$$\n",
    "$$X_i = UD_{j}V_{i}$$\n",
    "Where for every i, the first k columns of $$V_{i}$$ are the $$Q_{i}$$ while the other columns are gernerated randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_Q = NAL_1.multi_Q\n",
    "lv_0 = estimate_leverage_scores_from_orthogonal_matrix(previous_Q[0,:,:])\n",
    "lv_1 = estimate_leverage_scores_from_orthogonal_matrix(previous_Q[1,:,:])\n",
    "lv_2 = estimate_leverage_scores_from_orthogonal_matrix(previous_Q[2,:,:])\n",
    "lv_3 = estimate_leverage_scores_from_orthogonal_matrix(previous_Q[3,:,:])\n",
    "lv_4 = estimate_leverage_scores_from_orthogonal_matrix(previous_Q[4,:,:])\n",
    "lv_5 = estimate_leverage_scores_from_orthogonal_matrix(previous_Q[5,:,:])\n",
    "index_list = list(range(real_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the objective is Q and the initialization is Q_0 (the rectangular identity)\n",
    "We have with respect to the Schur-order (or the majorization):\n",
    "$$Q = Q_5 \\prec_{S} Q_4 \\prec_{S} Q_3 \\prec_{S} Q_2 \\prec_{S} Q_1 \\prec_{S} Q_0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXBTMzKzgomBmZoX/AUHyhhEXSwh9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0c8c3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(index_list[0:10], lv_0[0:10], 'c--',index_list[0:10], lv_1[0:10], 'k--', index_list[0:10], lv_2[0:10], 'r--', index_list[0:10], lv_3[0:10], 'b--',index_list[0:10], lv_4[0:10], 'g--',index_list[0:10], lv_5[0:10], 'y--')\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('leverage score')\n",
    "cyan_patch = mpatches.Patch(color='cyan', label='Q_0')\n",
    "black_patch = mpatches.Patch(color='black', label='Q_1')\n",
    "red_patch = mpatches.Patch(color='red', label='Q_2')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Q_3')\n",
    "green_patch = mpatches.Patch(color='green', label='Q_4')\n",
    "yellow_patch = mpatches.Patch(color='yellow', label='Q = Q_5')\n",
    "plt.legend(handles=[cyan_patch,black_patch,red_patch,blue_patch,green_patch,yellow_patch])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III-1-2 The case of a projection spectrum\n",
    "We mean by a projection spectrum matrix, a matrix with equal the first k singular values.\n",
    "We observe that the two distributions are very similar.... \\todo{reword}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3\n",
      "  0.3  0.3  0.3  0.3  0.3]\n",
      "[ 1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "[-0.7 -0.7 -0.7 -0.7 -0.7 -0.7  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3  0.3\n",
      "  0.3  0.3  0.3  0.3  0.3]\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mean and cov must have same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-02c52d928687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcov_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNAL_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNumrerical_Analysis_DPP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mversions_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlv_scores_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprojection_DPP_res_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNAL_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_error_for_projection_DPP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvolume_sampling_res_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNAL_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_error_for_volume_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdeterministic_selection_res_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNAL_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_for_deterministic_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-bdfa29c7ce79>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, N, real_dim, r, k, versions_number, mean, cov, lv_scores)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions_number\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_Q\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_orthonormal_matrix_with_leverage_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlv_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mversions_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'identity'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontruct_dataset_from_orthogonal_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_Q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontruct_dataset_from_orthogonal_matrix_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_Q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mversions_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtest_multi_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions_number\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c037df829359>\u001b[0m in \u001b[0;36mcontruct_dataset_from_orthogonal_matrix\u001b[0;34m(multi_Q, N, target_d, cov, mean, versions_number)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmulti_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversions_number\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversions_number\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mQ_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_orthogonal_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_Q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mean and cov must have same length"
     ]
    }
   ],
   "source": [
    "cov_2 = np.diag(np.concatenate(([1000,1000,1000,1,0.1],cov_test)))\n",
    "NAL_2 = Numrerical_Analysis_DPP(N,real_dim,r,k,versions_number,mean,cov_2,lv_scores_vector)\n",
    "projection_DPP_res_2 = NAL_2.get_expected_error_for_projection_DPP()\n",
    "volume_sampling_res_2 = NAL_2.get_expected_error_for_volume_sampling()\n",
    "deterministic_selection_res_2 = NAL_1.get_error_for_deterministic_selection()\n",
    "sum_U_res_2 = NAL_2.get_sum_k_leverage_scores()\n",
    "deterministic_upper_bound_res_2 = NAL_2.get_deterministic_upper_bound()\n",
    "\n",
    "results = [[\"Dataset\",\"Using Volume Sampling\",\"Using Projection DPP\",\"k-sum\",\"1/(1-epsilon)\",\"Using Deterministic Algorithm\"],[\"X_0\",volume_sampling_res_2[0],projection_DPP_res_2[0],sum_U_res_2[0],deterministic_upper_bound_res_2[0],deterministic_selection_res_2[0]],[\"X_1\",volume_sampling_res_2[1],projection_DPP_res_2[1],sum_U_res_2[1],deterministic_upper_bound_res_2[1],deterministic_selection_res_2[1]],\n",
    "          [\"X_2\",volume_sampling_res_2[2],projection_DPP_res_2[2],sum_U_res_2[2],deterministic_upper_bound_res_2[2],deterministic_selection_res_2[2]],[\"X_3\",volume_sampling_res_2[3],projection_DPP_res_2[3],sum_U_res_2[3],deterministic_upper_bound_res_2[3],deterministic_selection_res_2[3]],[\"X_4\",volume_sampling_res_2[4],projection_DPP_res_2[4],sum_U_res_2[4],deterministic_upper_bound_res_2[4],deterministic_selection_res_2[4]],[\"X_5\",volume_sampling_res_2[5],projection_DPP_res_2[5],sum_U_res_2[5],deterministic_upper_bound_res_2[5],deterministic_selection_res_2[5]]] \n",
    "display(HTML(\n",
    "    '<center><b>The expected approximation error (divided by the optimal error) according to a sampling scheme for different distribution</b><br><table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in results)\n",
    "        )\n",
    " ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### III-2 The influence of the \"spread\" of V\n",
    "In this section we investigate the influence of the \"spread\" (to be defined formally) of the cloud of points. We can change this \"spread\" by changing the initialization of the generator of orthogonal matrices: we replace the rectangular identity by \"other\" orthogonal matrices.  \n",
    "Technically, this boils down to change the generator mode in the constructor call from \"nonspread\" to \"spread\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.power(np.linspace(1, k, num=k),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrices_array = [ np.zeros((4,4)) for comb in combinations(range(5),4)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_sum = np.sum(matrices_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.]]), array([[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.]]), array([[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.]]), array([[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.]]), array([[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.]])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
